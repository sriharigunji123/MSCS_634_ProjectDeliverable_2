{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8ced4d2-ec84-4f47-baaa-9d6f554def48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(\"heart_disease_modified.csv\")\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44db37fe-d843-4987-b031-28a45e88728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here the Cleaned, Updated data set from deliverable 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6f9d33f-6c51-4bd7-96f3-0639fe7b1224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0   52    1   0       125  364.5    0        1    168.0      0      1.0   \n",
      "1   53    1   0       170  203.0    1        0    155.0      1      3.1   \n",
      "2   70    1   0       145  174.0    0        1    125.0      1      2.6   \n",
      "3   61    1   0       148  203.0    0        1    161.0      0      0.0   \n",
      "4   62    0   0       138  294.0    1        1    106.0      0      1.9   \n",
      "\n",
      "   slope  ca  thal  target  \n",
      "0      2   2     3       0  \n",
      "1      0   0     3       0  \n",
      "2      0   0     3       0  \n",
      "3      2   1     3       0  \n",
      "4      1   3     2       0  \n"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical variables (drop_first avoids dummy trap)\n",
    "df_encoded = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Preview to confirm changes\n",
    "print(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8770cd0f-3a27-479d-af4d-218b2468b543",
   "metadata": {},
   "source": [
    "Performed feature engineering using one-hot encoding on all categorical variables. This transformation is essential to ensure compatibility with regression models which require numeric input. Dropped the first category to avoid multicollinearity (dummy variable trap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "105967e8-2738-49cf-af8b-38d67b168625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X = df_encoded.drop('chol', axis=1)\n",
    "y = df_encoded['chol']\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d0a7a8-6ee6-4a9a-a9f3-2e2d9816c31b",
   "metadata": {},
   "source": [
    "Selected chol as the target variable for regression and used all other columns as predictors. Splitting the data ensures the model can be trained on one portion and tested on unseen data to evaluate generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a064c84a-7a78-43e5-b4cf-5358d421b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "# Initialize and train a Linear Regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# Initialize and train a Ridge Regression model (with regularization)\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using Ridge model\n",
    "y_pred_ridge = ridge.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9003cb6f-34fa-453f-bbde-b3ded341cb45",
   "metadata": {},
   "source": [
    "Trained two models: Linear Regression and Ridge Regression. Ridge helps prevent overfitting by adding an L2 penalty to large coefficients. Predictions were generated for both models on the same test dataset for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3b2fe20-9c18-4c2d-b9bb-afcba4b0cd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression → MSE: 1755.1686355912018 | RMSE: 41.89473279054542 | R²: 0.033255893395134906\n",
      "Ridge Regression  → MSE: 1754.487229643681 | RMSE: 41.886599642889145 | R²: 0.033631210712578574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Evaluate Linear Regression model\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)  # Mean Squared Error\n",
    "rmse_lr = np.sqrt(mse_lr)                      # Root Mean Squared Error\n",
    "r2_lr = r2_score(y_test, y_pred_lr)            # R-squared\n",
    "\n",
    "# Evaluate Ridge Regression model\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "rmse_ridge = np.sqrt(mse_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "# Print metrics for both models\n",
    "print(\"Linear Regression → MSE:\", mse_lr, \"| RMSE:\", rmse_lr, \"| R²:\", r2_lr)\n",
    "print(\"Ridge Regression  → MSE:\", mse_ridge, \"| RMSE:\", rmse_ridge, \"| R²:\", r2_ridge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc10ef7-6731-48c7-9427-1f1704a644af",
   "metadata": {},
   "source": [
    "Used three standard metrics to evaluate model performance: MSE, RMSE, and R². Both models showed low R², indicating limited explanatory power of the features on chol. Ridge slightly improved MSE, showing better generalization through regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0ed81d5-0f59-4ac1-82bf-16c6c268fbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression CV MSE: 2046.6489387676563\n",
      "Ridge Regression CV MSE: 2044.7081000309583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 5-fold cross-validation for Linear Regression\n",
    "cv_lr = cross_val_score(lr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Perform 5-fold cross-validation for Ridge Regression\n",
    "cv_ridge = cross_val_score(ridge, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Display average CV performance (convert negative to positive for MSE)\n",
    "print(\"Linear Regression CV MSE:\", -cv_lr.mean())\n",
    "print(\"Ridge Regression CV MSE:\", -cv_ridge.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbbb44f-36ac-4b62-b9bd-b754d75d912f",
   "metadata": {},
   "source": [
    "Applied 5-fold cross-validation to evaluate how well each model generalizes to new data. Ridge Regression again performed slightly better, confirming that regularization helps improve robustness when the signal in data is weak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f0f84c-2387-4d10-820b-b6f7fe7d8d13",
   "metadata": {},
   "source": [
    "Ridge Regression demonstrated more consistent results across training and testing phases and slightly outperformed Linear Regression during cross-validation. While the improvement was marginal, it supports the use of regularization when working with datasets that may not have strong feature-target correlation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
